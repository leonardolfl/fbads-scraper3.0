name: FB Ads Scraper Di√°rio

on:
  schedule:
    # Executa todo dia √†s 7h da manh√£ (10h UTC)
    - cron: '0 10 * * *'
  workflow_dispatch:

jobs:
  # -------------------------------
  # 1. SCRAPER WORKERS
  # -------------------------------
  scraper-workers:
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/playwright:v1.56.1-jammy
      options: --shm-size=1g

    strategy:
      matrix:
        worker_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9,
                       10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
                       20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
                       30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
                       40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
      fail-fast: false

    env:
      TOTAL_WORKERS: 50
      WORKER_INDEX: ${{ matrix.worker_index }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      LOG_LEVEL: info

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci --prefer-offline
      - run: node scraper.mjs

  # -------------------------------
  # 2. UPDATE EAGLE JSON
  # -------------------------------
  update-eagle-json:
    name: Atualizar eagle_offers_data.json
    runs-on: ubuntu-latest
    needs: scraper-workers   # s√≥ roda depois que todos os workers terminarem

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      EAGLE_UPDATE_URL: ${{ secrets.EAGLE_UPDATE_URL }}

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - run: npm ci --prefer-offline

      - name: ü¶Ö Gerar e enviar eagle_offers_data.json
        run: node update-eagle-json.mjs
